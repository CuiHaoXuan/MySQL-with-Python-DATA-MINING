{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:32.058246Z",
     "start_time": "2019-09-18T06:56:32.036305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  数值计算和统计基础\\n\\n常用数学、统计方法\\n \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  数值计算和统计基础\n",
    "\n",
    "常用数学、统计方法\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.078557Z",
     "start_time": "2019-09-18T06:56:32.084175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1  key2 key3\n",
      "a   4.0   1.0    1\n",
      "b   5.0   2.0    2\n",
      "c   3.0   NaN    3\n",
      "d   NaN   4.0    j\n",
      "e   2.0   5.0    k\n",
      "float64 float64 object\n",
      "-----\n",
      "key1    3.5\n",
      "key2    3.0\n",
      "dtype: float64 <class 'pandas.core.series.Series'>\n",
      "单独统计一列: 3.0\n",
      "-----\n",
      "a    2.5\n",
      "b    3.5\n",
      "c    3.0\n",
      "d    4.0\n",
      "e    3.5\n",
      "dtype: float64\n",
      "-----\n",
      "key1   NaN\n",
      "key2   NaN\n",
      "dtype: float64\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 基本参数：axis、skipna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'key1':[4,5,3,np.nan,2],\n",
    "                 'key2':[1,2,np.nan,4,5],\n",
    "                 'key3':[1,2,3,'j','k']},\n",
    "                 index = ['a','b','c','d','e'])\n",
    "print(df)\n",
    "print(df['key1'].dtype,df['key2'].dtype,df['key3'].dtype)\n",
    "print('-----')\n",
    "\n",
    "m1 = df.mean()\n",
    "print(m1,type(m1))\n",
    "print('单独统计一列:',df['key2'].mean())\n",
    "print('-----')\n",
    "# np.nan ：空值\n",
    "# .mean()计算均值\n",
    "# 只统计数字列\n",
    "# 可以通过索引单独统计一列\n",
    "\n",
    "m2 = df.mean(axis=1)\n",
    "print(m2)\n",
    "print('-----')\n",
    "# axis参数：默认为0，以列来计算，axis=1，以行来计算，这里就按照行来汇总了\n",
    "\n",
    "m3 = df.mean(skipna=False)\n",
    "print(m3)\n",
    "print('-----')\n",
    "# skipna参数：是否忽略NaN，默认True，如False，有NaN的列统计结果仍未NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.088489Z",
     "start_time": "2019-09-18T06:56:33.084517Z"
    }
   },
   "outputs": [],
   "source": [
    "# 主要数学计算方法，可用于Series和DataFrame（1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.130415Z",
     "start_time": "2019-09-18T06:56:33.097468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1      key2\n",
      "0     0  8.178238\n",
      "1     1  2.746025\n",
      "2     2  2.305404\n",
      "3     3  9.212598\n",
      "4     4  6.733532\n",
      "5     5  6.112399\n",
      "6     6  5.548033\n",
      "7     7  5.753055\n",
      "8     8  7.935598\n",
      "9     9  6.569297\n",
      "-----\n",
      "key1    10\n",
      "key2    10\n",
      "dtype: int64 → count统计非Na值的数量\n",
      "\n",
      "key1    0.000000\n",
      "key2    2.305404\n",
      "dtype: float64 → min统计最小值\n",
      " 9.212598465981031 → max统计最大值\n",
      "\n",
      "key1    6.750000\n",
      "key2    7.635082\n",
      "Name: 0.75, dtype: float64 → quantile统计分位数，参数q确定位置\n",
      "\n",
      "key1    45.000000\n",
      "key2    61.094179\n",
      "dtype: float64 → sum求和\n",
      "\n",
      "key1    4.500000\n",
      "key2    6.109418\n",
      "dtype: float64 → mean求平均值\n",
      "\n",
      "key1    4.500000\n",
      "key2    6.340848\n",
      "dtype: float64 → median求算数中位数，50%分位数\n",
      "\n",
      "key1    3.027650\n",
      "key2    2.212861\n",
      "dtype: float64 \n",
      " key1    9.166667\n",
      "key2    4.896754\n",
      "dtype: float64 → std,var分别求标准差，方差\n",
      "\n",
      "key1    0.000000\n",
      "key2   -0.617145\n",
      "dtype: float64 → skew样本的偏度\n",
      "\n",
      "key1   -1.20000\n",
      "key2   -0.15364\n",
      "dtype: float64 → kurt样本的峰度\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1':np.arange(10),\n",
    "                  'key2':np.random.rand(10)*10})\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(df.count(),'→ count统计非Na值的数量\\n')\n",
    "print(df.min(),'→ min统计最小值\\n',df['key2'].max(),'→ max统计最大值\\n')\n",
    "print(df.quantile(q=0.75),'→ quantile统计分位数，参数q确定位置\\n')\n",
    "print(df.sum(),'→ sum求和\\n')\n",
    "print(df.mean(),'→ mean求平均值\\n')\n",
    "print(df.median(),'→ median求算数中位数，50%分位数\\n')\n",
    "print(df.std(),'\\n',df.var(),'→ std,var分别求标准差，方差\\n')\n",
    "print(df.skew(),'→ skew样本的偏度\\n')\n",
    "print(df.kurt(),'→ kurt样本的峰度\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.384733Z",
     "start_time": "2019-09-18T06:56:33.134369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1      key2  key1_s     key2_s\n",
      "0     0  8.178238       0   8.178238\n",
      "1     1  2.746025       1  10.924263\n",
      "2     2  2.305404       3  13.229667\n",
      "3     3  9.212598       6  22.442266\n",
      "4     4  6.733532      10  29.175797\n",
      "5     5  6.112399      15  35.288196\n",
      "6     6  5.548033      21  40.836228\n",
      "7     7  5.753055      28  46.589284\n",
      "8     8  7.935598      36  54.524882\n",
      "9     9  6.569297      45  61.094179 → cumsum样本的累计和\n",
      "\n",
      "   key1      key2  key1_s     key2_s  key1_p        key2_p\n",
      "0     0  8.178238       0   8.178238       0  8.178238e+00\n",
      "1     1  2.746025       1  10.924263       0  2.245764e+01\n",
      "2     2  2.305404       3  13.229667       0  5.177394e+01\n",
      "3     3  9.212598       6  22.442266       0  4.769725e+02\n",
      "4     4  6.733532      10  29.175797       0  3.211710e+03\n",
      "5     5  6.112399      15  35.288196       0  1.963125e+04\n",
      "6     6  5.548033      21  40.836228       0  1.089148e+05\n",
      "7     7  5.753055      28  46.589284       0  6.265929e+05\n",
      "8     8  7.935598      36  54.524882       0  4.972390e+06\n",
      "9     9  6.569297      45  61.094179       0  3.266511e+07 → cumprod样本的累计积\n",
      "\n",
      "   key1      key2  key1_s     key2_s  key1_p        key2_p\n",
      "0   0.0  8.178238     0.0   8.178238     0.0  8.178238e+00\n",
      "1   1.0  8.178238     1.0  10.924263     0.0  2.245764e+01\n",
      "2   2.0  8.178238     3.0  13.229667     0.0  5.177394e+01\n",
      "3   3.0  9.212598     6.0  22.442266     0.0  4.769725e+02\n",
      "4   4.0  9.212598    10.0  29.175797     0.0  3.211710e+03\n",
      "5   5.0  9.212598    15.0  35.288196     0.0  1.963125e+04\n",
      "6   6.0  9.212598    21.0  40.836228     0.0  1.089148e+05\n",
      "7   7.0  9.212598    28.0  46.589284     0.0  6.265929e+05\n",
      "8   8.0  9.212598    36.0  54.524882     0.0  4.972390e+06\n",
      "9   9.0  9.212598    45.0  61.094179     0.0  3.266511e+07 \n",
      "    key1      key2  key1_s    key2_s  key1_p    key2_p\n",
      "0   0.0  8.178238     0.0  8.178238     0.0  8.178238\n",
      "1   0.0  2.746025     0.0  8.178238     0.0  8.178238\n",
      "2   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "3   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "4   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "5   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "6   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "7   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "8   0.0  2.305404     0.0  8.178238     0.0  8.178238\n",
      "9   0.0  2.305404     0.0  8.178238     0.0  8.178238 → cummax,cummin分别求累计最大值，累计最小值\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 主要数学计算方法，可用于Series和DataFrame（2）\n",
    "\n",
    "df['key1_s'] = df['key1'].cumsum()\n",
    "df['key2_s'] = df['key2'].cumsum()\n",
    "print(df,'→ cumsum样本的累计和\\n')\n",
    "\n",
    "df['key1_p'] = df['key1'].cumprod()\n",
    "df['key2_p'] = df['key2'].cumprod()\n",
    "print(df,'→ cumprod样本的累计积\\n')\n",
    "\n",
    "print(df.cummax(),'\\n',df.cummin(),'→ cummax,cummin分别求累计最大值，累计最小值\\n')\n",
    "# 会填充key1，和key2的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.403646Z",
     "start_time": "2019-09-18T06:56:33.386692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "1     s\n",
      "2     d\n",
      "3     v\n",
      "4     a\n",
      "5     s\n",
      "6     d\n",
      "7     c\n",
      "8     f\n",
      "9     g\n",
      "10    g\n",
      "dtype: object\n",
      "['a' 's' 'd' 'v' 'c' 'f' 'g'] <class 'numpy.ndarray'>\n",
      "0    a\n",
      "1    s\n",
      "2    d\n",
      "3    v\n",
      "4    c\n",
      "5    f\n",
      "6    g\n",
      "dtype: object\n",
      "['a' 'c' 'd' 'f' 'g' 's' 'v']\n"
     ]
    }
   ],
   "source": [
    "# 唯一值：.unique()\n",
    "\n",
    "s = pd.Series(list('asdvasdcfgg'))\n",
    "sq = s.unique()\n",
    "print(s)\n",
    "print(sq,type(sq))\n",
    "print(pd.Series(sq))\n",
    "# 得到一个唯一值数组\n",
    "# 通过pd.Series重新变成新的Series\n",
    "\n",
    "sq.sort()\n",
    "print(sq)\n",
    "# 重新排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.507369Z",
     "start_time": "2019-09-18T06:56:33.411625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    2\n",
      "c    1\n",
      "a    2\n",
      "s    2\n",
      "v    1\n",
      "f    1\n",
      "g    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 值计数：.value_counts()\n",
    "\n",
    "sc = s.value_counts(sort = False)  # 也可以这样写：pd.value_counts(sc, sort = False)\n",
    "print(sc)\n",
    "# 得到一个新的Series，计算出不同值出现的频率\n",
    "# sort参数：排序，默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.540281Z",
     "start_time": "2019-09-18T06:56:33.512356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    11\n",
      "2    12\n",
      "3    13\n",
      "4    14\n",
      "dtype: int32\n",
      "  key1  key2\n",
      "0    a     4\n",
      "1    s     5\n",
      "2    d     6\n",
      "3    c     7\n",
      "4    b     8\n",
      "5    v     9\n",
      "6    a    10\n",
      "7    s    11\n",
      "8    d    12\n",
      "-----\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n",
      "    key1   key2\n",
      "0   True  False\n",
      "1  False  False\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False   True\n",
      "5  False  False\n",
      "6   True  False\n",
      "7  False  False\n",
      "8  False  False\n"
     ]
    }
   ],
   "source": [
    "# 成员资格：.isin()\n",
    "\n",
    "s = pd.Series(np.arange(10,15))\n",
    "df = pd.DataFrame({'key1':list('asdcbvasd'),\n",
    "                  'key2':np.arange(4,13)})\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.isin([5,14]))\n",
    "print(df.isin(['a','bc','10',8]))\n",
    "# 用[]表示\n",
    "# 得到一个布尔值的Series或者Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:12:49.122788Z",
     "start_time": "2019-09-18T03:12:49.077908Z"
    },
    "collapsed": true
   },
   "source": [
    "文本数据\n",
    "Pandas针对字符串配备的一套方法，使其易于对数组的每个元素进行操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过str访问，且自动排除丢失/ NA值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.586159Z",
     "start_time": "2019-09-18T06:56:33.556244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          A\n",
      "1          b\n",
      "2          C\n",
      "3    bbhello\n",
      "4        123\n",
      "5        NaN\n",
      "6         hj\n",
      "dtype: object\n",
      "  key1  key2\n",
      "0    a   hee\n",
      "1    b    fv\n",
      "2    c     w\n",
      "3    d  hija\n",
      "4    e   123\n",
      "5    f   NaN\n",
      "-----\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    2.0\n",
      "4    0.0\n",
      "5    NaN\n",
      "6    0.0\n",
      "dtype: float64\n",
      "0     HEE\n",
      "1      FV\n",
      "2       W\n",
      "3    HIJA\n",
      "4     123\n",
      "5     NaN\n",
      "Name: key2, dtype: object\n",
      "-----\n",
      "  KEY1  KEY2\n",
      "0    a   hee\n",
      "1    b    fv\n",
      "2    c     w\n",
      "3    d  hija\n",
      "4    e   123\n",
      "5    f   NaN\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['A','b','C','bbhello','123',np.nan,'hj'])\n",
    "df = pd.DataFrame({'key1':list('abcdef'),\n",
    "                  'key2':['hee','fv','w','hija','123',np.nan]})\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.str.count('b'))\n",
    "print(df['key2'].str.upper())\n",
    "print('-----')\n",
    "# 直接通过.str调用字符串方法\n",
    "# 可以对Series、Dataframe使用\n",
    "# 自动过滤NaN值\n",
    "\n",
    "df.columns = df.columns.str.upper()\n",
    "print(df)\n",
    "# df.columns是一个Index对象，也可使用.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串常用方法（1） - lower，upper，len，startswith，endswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.610094Z",
     "start_time": "2019-09-18T06:56:33.590148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          a\n",
      "1          b\n",
      "2    bbhello\n",
      "3        123\n",
      "4        NaN\n",
      "dtype: object → lower小写\n",
      "\n",
      "0          A\n",
      "1          B\n",
      "2    BBHELLO\n",
      "3        123\n",
      "4        NaN\n",
      "dtype: object → upper大写\n",
      "\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    7.0\n",
      "3    3.0\n",
      "4    NaN\n",
      "dtype: float64 → len字符长度\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4      NaN\n",
      "dtype: object → 判断起始是否为a\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4      NaN\n",
      "dtype: object → 判断结束是否为3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['A','b','bbhello','123',np.nan])\n",
    "print(s.str.lower(),'→ lower小写\\n')\n",
    "print(s.str.upper(),'→ upper大写\\n')\n",
    "print(s.str.len(),'→ len字符长度\\n')\n",
    "print(s.str.startswith('b'),'→ 判断起始是否为a\\n')\n",
    "print(s.str.endswith('3'),'→ 判断结束是否为3\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串常用方法（2） - strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.642009Z",
     "start_time": "2019-09-18T06:56:33.612088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       jack\n",
      "1      jill \n",
      "2     jesse \n",
      "3      frank\n",
      "dtype: object\n",
      "    Column A    Column B \n",
      "0    1.216927   -0.773989\n",
      "1   -0.019748    0.038672\n",
      "2    1.189452   -0.966575\n",
      "-----\n",
      "0     jack\n",
      "1     jill\n",
      "2    jesse\n",
      "3    frank\n",
      "dtype: object\n",
      "0      jack\n",
      "1     jill \n",
      "2    jesse \n",
      "3     frank\n",
      "dtype: object\n",
      "0      jack\n",
      "1      jill\n",
      "2     jesse\n",
      "3     frank\n",
      "dtype: object\n",
      "   Column A  Column B\n",
      "0  1.216927 -0.773989\n",
      "1 -0.019748  0.038672\n",
      "2  1.189452 -0.966575\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([' jack', 'jill ', ' jesse ', 'frank'])\n",
    "df = pd.DataFrame(np.random.randn(3, 2), columns=[' Column A ', ' Column B '],\n",
    "                  index=range(3))\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.str.strip())  # 去除字符串中的空格\n",
    "print(s.str.lstrip())  # 去除字符串中的左空格\n",
    "print(s.str.rstrip())  # 去除字符串中的右空格\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "print(df)\n",
    "# 这里去掉了columns的前后空格，但没有去掉中间空格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 字符串常用方法（3） - replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.670931Z",
     "start_time": "2019-09-18T06:56:33.649987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -Column-A-  -Column-B-\n",
      "0    0.635504   -1.006322\n",
      "1    0.591760    0.744374\n",
      "2   -1.626067    0.025827\n",
      "   heheColumn-A-  heheColumn-B-\n",
      "0       0.635504      -1.006322\n",
      "1       0.591760       0.744374\n",
      "2      -1.626067       0.025827\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(3, 2), columns=[' Column A ', ' Column B '],\n",
    "                  index=range(3))\n",
    "df.columns = df.columns.str.replace(' ','-')\n",
    "print(df)\n",
    "# 替换\n",
    "\n",
    "df.columns = df.columns.str.replace('-','hehe',n=1)\n",
    "print(df)\n",
    "# n：替换个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.725785Z",
     "start_time": "2019-09-18T06:56:33.673923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [a, b, c]\n",
      "1    [1, 2, 3]\n",
      "2          NaN\n",
      "3          NaN\n",
      "dtype: object\n",
      "-----\n",
      "['a', 'b', 'c']\n",
      "-----\n",
      "0      a\n",
      "1      1\n",
      "2    NaN\n",
      "3    NaN\n",
      "dtype: object\n",
      "0      b\n",
      "1      2\n",
      "2    NaN\n",
      "3    NaN\n",
      "dtype: object\n",
      "-----\n",
      "     0    1    2\n",
      "0    a    b    c\n",
      "1    1    2    3\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  NaN  NaN\n",
      "     0    1\n",
      "0    a  b,c\n",
      "1    1  2,3\n",
      "2  NaN  NaN\n",
      "3  NaN  NaN\n",
      "     0    1\n",
      "0  a,b    c\n",
      "1  1,2    3\n",
      "2  NaN  NaN\n",
      "3  NaN  NaN\n",
      "-----\n",
      "0    [a, b, c]\n",
      "1    [1, 2, 3]\n",
      "2          NaN\n",
      "Name: key2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 字符串常用方法（4） - split、rsplit\n",
    "\n",
    "s = pd.Series(['a,b,c','1,2,3',['a,,,c'],np.nan])\n",
    "print(s.str.split(','))\n",
    "print('-----')\n",
    "# 类似字符串的split\n",
    "\n",
    "print(s.str.split(',')[0])\n",
    "print('-----')\n",
    "# 直接索引得到一个list\n",
    "\n",
    "print(s.str.split(',').str[0])\n",
    "print(s.str.split(',').str.get(1))\n",
    "print('-----')\n",
    "# 可以使用get或[]符号访问拆分列表中的元素\n",
    "\n",
    "print(s.str.split(',', expand=True))\n",
    "print(s.str.split(',', expand=True, n = 1))\n",
    "print(s.str.rsplit(',', expand=True, n = 1))\n",
    "print('-----')\n",
    "# 可以使用expand可以轻松扩展此操作以返回DataFrame\n",
    "# n参数限制分割数\n",
    "# rsplit类似于split，反向工作，即从字符串的末尾到字符串的开头\n",
    "\n",
    "df = pd.DataFrame({'key1':['a,b,c','1,2,3',[':,., ']],\n",
    "                  'key2':['a-b-c','1-2-3',[':-.- ']]})\n",
    "print(df['key2'].str.split('-'))\n",
    "# Dataframe使用split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.753711Z",
     "start_time": "2019-09-18T06:56:33.729777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      A\n",
      "1      b\n",
      "2      C\n",
      "3      b\n",
      "4      1\n",
      "5    NaN\n",
      "6      h\n",
      "dtype: object\n",
      "0      A\n",
      "1      b\n",
      "2      C\n",
      "3     bb\n",
      "4     12\n",
      "5    NaN\n",
      "6     hj\n",
      "dtype: object\n",
      "0      h\n",
      "1      f\n",
      "2      w\n",
      "3      h\n",
      "4      1\n",
      "5    NaN\n",
      "Name: key2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 字符串索引\n",
    "\n",
    "s = pd.Series(['A','b','C','bbhello','123',np.nan,'hj'])\n",
    "df = pd.DataFrame({'key1':list('abcdef'),\n",
    "                  'key2':['hee','fv','w','hija','123',np.nan]})\n",
    "\n",
    "print(s.str[0])  # 取第一个字符串\n",
    "print(s.str[:2])  # 取前两个字符串\n",
    "print(df['key2'].str[0]) \n",
    "# str之后和字符串本身索引方式相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######## 本节课有作业，请查看 “课程作业.docx”  ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:33.767673Z",
     "start_time": "2019-09-18T06:56:33.761690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n 合并 merge、join\\n\\nPandas具有全功能的，高性能内存中连接操作，与SQL等关系数据库非常相似\\n\\npd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\\n         left_index=False, right_index=False, sort=True,\\n         suffixes=('_x', '_y'), copy=True, indicator=False)\\n \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " 合并 merge、join\n",
    "\n",
    "Pandas具有全功能的，高性能内存中连接操作，与SQL等关系数据库非常相似\n",
    "\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.075881Z",
     "start_time": "2019-09-18T06:56:33.781637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "------\n",
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# merge合并 → 类似excel的vlookup\n",
    "\n",
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "df3 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df4 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(pd.merge(df1, df2, on='key'))\n",
    "print('------')\n",
    "# left：第一个df\n",
    "# right：第二个df\n",
    "# on：参考键\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2']))\n",
    "# 多个链接键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.120727Z",
     "start_time": "2019-09-18T06:56:34.077876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n",
      "------\n",
      "  key1 key2    A    B    C    D\n",
      "0   K0   K0   A0   B0   C0   D0\n",
      "1   K0   K1   A1   B1  NaN  NaN\n",
      "2   K1   K0   A2   B2   C1   D1\n",
      "3   K1   K0   A2   B2   C2   D2\n",
      "4   K2   K1   A3   B3  NaN  NaN\n",
      "5   K2   K0  NaN  NaN   C3   D3\n",
      "------\n",
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "------\n",
      "  key1 key2    A    B   C   D\n",
      "0   K0   K0   A0   B0  C0  D0\n",
      "1   K1   K0   A2   B2  C1  D1\n",
      "2   K1   K0   A2   B2  C2  D2\n",
      "3   K2   K0  NaN  NaN  C3  D3\n"
     ]
    }
   ],
   "source": [
    "# 参数how → 合并方式\n",
    "\n",
    "print(pd.merge(df3, df4,on=['key1','key2'], how = 'inner'))  \n",
    "print('------')\n",
    "# inner：默认，取交集\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'outer'))  \n",
    "print('------')\n",
    "# outer：取并集，数据缺失范围NaN\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'left'))  \n",
    "print('------')\n",
    "# left：按照df3为参考合并，数据缺失范围NaN\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'right'))  \n",
    "# right：按照df4为参考合并，数据缺失范围NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.158627Z",
     "start_time": "2019-09-18T06:56:34.126712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lkey  data1 rkey  date2\n",
      "0    b      0    b      1\n",
      "1    b      1    b      1\n",
      "2    b      6    b      1\n",
      "3    a      2    a      0\n",
      "4    a      4    a      0\n",
      "5    a      5    a      0\n",
      "------\n",
      "  key  data1  date2\n",
      "0   a      0    100\n",
      "1   b      1    101\n",
      "2   c      2    102\n",
      "3   d      3    103\n",
      "5   e      5    104\n"
     ]
    }
   ],
   "source": [
    "# 参数 left_on, right_on, left_index, right_index → 当键不为一个列时，可以单独设置左键与右键\n",
    "\n",
    "df1 = pd.DataFrame({'lkey':list('bbacaab'),\n",
    "                   'data1':range(7)})\n",
    "df2 = pd.DataFrame({'rkey':list('abd'),\n",
    "                   'date2':range(3)})\n",
    "print(pd.merge(df1, df2, left_on='lkey', right_on='rkey'))\n",
    "print('------')\n",
    "# df1以‘lkey’为键，df2以‘rkey’为键\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('abcdfeg'),\n",
    "                   'data1':range(7)})\n",
    "df2 = pd.DataFrame({'date2':range(100,105)},\n",
    "                  index = list('abcde'))\n",
    "print(pd.merge(df1, df2, left_on='key', right_index=True))\n",
    "# df1以‘key’为键，df2以index为键\n",
    "# left_index：为True时，第一个df以index为键，默认False\n",
    "# right_index：为True时，第二个df以index为键，默认False\n",
    "\n",
    "# 所以left_on, right_on, left_index, right_index可以相互组合：\n",
    "# left_on + right_on, left_on + right_index, left_index + right_on, left_index + right_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.211523Z",
     "start_time": "2019-09-18T06:56:34.174583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data1  date2\n",
      "0   b    1.0    2.0\n",
      "1   b    3.0    2.0\n",
      "2   b    7.0    2.0\n",
      "3   a    2.0   11.0\n",
      "4   a    5.0   11.0\n",
      "5   a    9.0   11.0\n",
      "6   c    4.0    NaN\n",
      "7   d    NaN   33.0\n",
      "  key  data1  date2\n",
      "0   a    2.0   11.0\n",
      "1   a    5.0   11.0\n",
      "2   a    9.0   11.0\n",
      "3   b    1.0    2.0\n",
      "4   b    3.0    2.0\n",
      "5   b    7.0    2.0\n",
      "6   c    4.0    NaN\n",
      "7   d    NaN   33.0\n",
      "------\n",
      "  key  data1  date2\n",
      "3   b    1.0    2.0\n",
      "0   a    2.0   11.0\n",
      "4   b    3.0    2.0\n",
      "6   c    4.0    NaN\n",
      "1   a    5.0   11.0\n",
      "5   b    7.0    2.0\n",
      "2   a    9.0   11.0\n",
      "7   d    NaN   33.0\n"
     ]
    }
   ],
   "source": [
    "# 参数 sort\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('bbacaab'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'date2':[11,2,33]})\n",
    "x1 = pd.merge(df1,df2, on = 'key', how = 'outer')\n",
    "x2 = pd.merge(df1,df2, on = 'key', sort=True, how = 'outer')\n",
    "print(x1)\n",
    "print(x2)\n",
    "print('------')\n",
    "# sort：按照字典顺序通过 连接键 对结果DataFrame进行排序。默认为False，设置为False会大幅提高性能\n",
    "\n",
    "print(x2.sort_values('data1'))\n",
    "# 也可直接用Dataframe的排序方法：sort_values，sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.293267Z",
     "start_time": "2019-09-18T06:56:34.214514Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "     A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n",
      "      A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n",
      "-----\n",
      "  key  data1\n",
      "0   b      1\n",
      "1   b      3\n",
      "2   a      2\n",
      "3   c      4\n",
      "4   a      5\n",
      "5   a      9\n",
      "6   b      7\n",
      "  key  date2\n",
      "0   a     11\n",
      "1   b      2\n",
      "2   d     33\n",
      "  key_1  data1 key_2  date2\n",
      "0     b      1     a     11\n",
      "1     b      3     b      2\n",
      "2     a      2     d     33\n",
      "  key  data1  date2\n",
      "0   b      1   11.0\n",
      "1   b      3    2.0\n",
      "2   a      2   33.0\n",
      "3   c      4    NaN\n",
      "4   a      5    NaN\n",
      "5   a      9    NaN\n",
      "6   b      7    NaN\n",
      "-----\n",
      "    A   B key\n",
      "0  A0  B0  K0\n",
      "1  A1  B1  K1\n",
      "2  A2  B2  K0\n",
      "3  A3  B3  K1\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K1  C1  D1\n",
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K0  C0  D0\n",
      "3  A3  B3  K1  C1  D1\n"
     ]
    }
   ],
   "source": [
    "# pd.join() → 直接通过索引链接\n",
    "\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                    index=['K0', 'K1', 'K2'])\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D2', 'D3']},\n",
    "                     index=['K0', 'K2', 'K3'])\n",
    "print(left)\n",
    "print(right)\n",
    "print(left.join(right))\n",
    "print(left.join(right, how='outer'))  \n",
    "print('-----')\n",
    "# 等价于：pd.merge(left, right, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('bbacaab'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'date2':[11,2,33]})\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1, df2, left_index=True, right_index=True, suffixes=('_1', '_2')))  \n",
    "print(df1.join(df2['date2']))\n",
    "print('-----')\n",
    "# suffixes=('_x', '_y')默认\n",
    "\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "right = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                      'D': ['D0', 'D1']},\n",
    "                     index=['K0', 'K1'])\n",
    "print(left)\n",
    "print(right)\n",
    "print(left.join(right, on = 'key'))\n",
    "# 等价于pd.merge(left, right, left_on='key', right_index=True, how='left', sort=False);\n",
    "# left的‘key’和right的index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######## 本节课有作业，请查看 “课程作业.docx”  ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.303239Z",
     "start_time": "2019-09-18T06:56:34.297257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  连接与修补 concat、combine_first\\n\\n连接 - 沿轴执行连接操作\\n\\npd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\\n          keys=None, levels=None, names=None, verify_integrity=False,\\n          copy=True)\\n \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  连接与修补 concat、combine_first\n",
    "\n",
    "连接 - 沿轴执行连接操作\n",
    "\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.357098Z",
     "start_time": "2019-09-18T06:56:34.321194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "c    2\n",
      "d    4\n",
      "e    3\n",
      "h    3\n",
      "dtype: int64\n",
      "-----\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  NaN  2.0\n",
      "c  2.0  NaN\n",
      "d  NaN  4.0\n",
      "e  NaN  3.0\n",
      "h  3.0  NaN\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 连接：concat\n",
    "\n",
    "s1 = pd.Series([1,2,3])\n",
    "s2 = pd.Series([2,3,4])\n",
    "s3 = pd.Series([1,2,3],index = ['a','c','h'])\n",
    "s4 = pd.Series([2,3,4],index = ['b','e','d'])\n",
    "print(pd.concat([s1,s2]))\n",
    "print(pd.concat([s3,s4]).sort_index())\n",
    "print('-----')\n",
    "# 默认axis=0，行+行\n",
    "\n",
    "print(pd.concat([s3,s4], axis=1))\n",
    "print('-----')\n",
    "# axis=1,列+列，成为一个Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.394994Z",
     "start_time": "2019-09-18T06:56:34.372055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0\n",
      "   0  1\n",
      "b  2  2\n",
      "c  3  3\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "d  NaN  4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 连接方式：join，join_axes\n",
    "\n",
    "s5 = pd.Series([1,2,3],index = ['a','b','c'])\n",
    "s6 = pd.Series([2,3,4],index = ['b','c','d'])\n",
    "print(pd.concat([s5,s6], axis= 1))\n",
    "print(pd.concat([s5,s6], axis= 1, join='inner'))\n",
    "print(pd.concat([s5,s6], axis= 1, join_axes=[['a','b','d']]))\n",
    "# join：{'inner'，'outer'}，默认为“outer”。如何处理其他轴上的索引。outer为联合和inner为交集。\n",
    "# join_axes：指定联合的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.429903Z",
     "start_time": "2019-09-18T06:56:34.400987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one  a    1\n",
      "     b    2\n",
      "     c    3\n",
      "two  b    2\n",
      "     c    3\n",
      "     d    4\n",
      "dtype: int64 <class 'pandas.core.series.Series'>\n",
      "MultiIndex(levels=[['one', 'two'], ['a', 'b', 'c', 'd']],\n",
      "           codes=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 1, 2, 3]])\n",
      "-----\n",
      "   one  two\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0 <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# 覆盖列名\n",
    "\n",
    "sre = pd.concat([s5,s6], keys = ['one','two'])\n",
    "print(sre,type(sre))\n",
    "print(sre.index)\n",
    "print('-----')\n",
    "# keys：序列，默认值无。使用传递的键作为最外层构建层次索引\n",
    "\n",
    "sre = pd.concat([s5,s6], axis=1, keys = ['one','two'])\n",
    "print(sre,type(sre))\n",
    "# axis = 1, 覆盖列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.537613Z",
     "start_time": "2019-09-18T06:56:34.434888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  NaN  3.0  5.0\n",
      "1 -4.6  NaN  NaN\n",
      "2  NaN  7.0  NaN\n",
      "      0    1    2\n",
      "1 -42.6  NaN -8.2\n",
      "2  -5.0  1.6  4.0\n",
      "     0    1    2\n",
      "0  NaN  3.0  5.0\n",
      "1 -4.6  NaN -8.2\n",
      "2 -5.0  7.0  4.0\n",
      "-----\n",
      "      0    1    2\n",
      "0   NaN  3.0  5.0\n",
      "1 -42.6  NaN -8.2\n",
      "2  -5.0  1.6  4.0\n"
     ]
    }
   ],
   "source": [
    "# 修补 pd.combine_first()\n",
    "\n",
    "df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan],[np.nan, 7., np.nan]])\n",
    "df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5., 1.6, 4]],index=[1, 2])\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(df1.combine_first(df2))\n",
    "print('-----')\n",
    "# 根据index，df1的空值被df2替代\n",
    "# 如果df2的index多于df1，则更新到df1上，比如index=['a',1]\n",
    "\n",
    "df1.update(df2)\n",
    "print(df1)\n",
    "# update，直接df2覆盖df1，相同index位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.551575Z",
     "start_time": "2019-09-18T06:56:34.546589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n 去重及替换\\n\\n.duplicated / .replace\\n \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " 去重及替换\n",
    "\n",
    ".duplicated / .replace\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.594461Z",
     "start_time": "2019-09-18T06:56:34.558559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6      True\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "dtype: bool\n",
      "0    1\n",
      "4    2\n",
      "7    3\n",
      "8    4\n",
      "9    5\n",
      "dtype: int64\n",
      "-----\n",
      "0    1\n",
      "4    2\n",
      "7    3\n",
      "8    4\n",
      "9    5\n",
      "dtype: int64\n",
      "-----\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: key2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 去重 .duplicated\n",
    "\n",
    "s = pd.Series([1,1,1,1,2,2,2,3,4,5,5,5,5])\n",
    "print(s.duplicated())\n",
    "print(s[s.duplicated() == False])\n",
    "print('-----')\n",
    "# 判断是否重复\n",
    "# 通过布尔判断，得到不重复的值\n",
    "\n",
    "s_re = s.drop_duplicates()\n",
    "print(s_re)\n",
    "print('-----')\n",
    "# drop.duplicates移除重复\n",
    "# inplace参数：是否替换原值，默认False\n",
    "\n",
    "df = pd.DataFrame({'key1':['a','a',3,4,5],\n",
    "                  'key2':['a','a','b','b','c']})\n",
    "print(df.duplicated())\n",
    "print(df['key2'].duplicated())\n",
    "# Dataframe中使用duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.614410Z",
     "start_time": "2019-09-18T06:56:34.600448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1      s\n",
      "2      c\n",
      "3    NaN\n",
      "4    NaN\n",
      "5      z\n",
      "6      s\n",
      "7      d\n",
      "dtype: object\n",
      "0    NaN\n",
      "1    NaN\n",
      "2      c\n",
      "3    NaN\n",
      "4    NaN\n",
      "5      z\n",
      "6    NaN\n",
      "7      d\n",
      "dtype: object\n",
      "0    hello world!\n",
      "1             123\n",
      "2               c\n",
      "3    hello world!\n",
      "4    hello world!\n",
      "5               z\n",
      "6             123\n",
      "7               d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 替换 .replace\n",
    "\n",
    "s = pd.Series(list('ascaazsd'))\n",
    "print(s.replace('a', np.nan))\n",
    "print(s.replace(['a','s'] ,np.nan))\n",
    "print(s.replace({'a':'hello world!','s':123}))\n",
    "# 可一次性替换一个值或多个值\n",
    "# 可传入列表或字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:51.806369Z",
     "start_time": "2019-09-18T06:56:51.800386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  数据分组\\n\\n分组统计 - groupby功能\\n\\n① 根据某些条件将数据拆分成组\\n② 对每个组独立应用函数\\n③ 将结果合并到一个数据结构中\\n\\nDataframe在行（axis=0）或列（axis=1）上进行分组，将一个函数应用到各个分组并产生一个新值，然后函数执行结果被合并到最终的结果对象中。\\n\\ndf.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\\n \\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  数据分组\n",
    "\n",
    "分组统计 - groupby功能\n",
    "\n",
    "① 根据某些条件将数据拆分成组\n",
    "② 对每个组独立应用函数\n",
    "③ 将结果合并到一个数据结构中\n",
    "\n",
    "Dataframe在行（axis=0）或列（axis=1）上进行分组，将一个函数应用到各个分组并产生一个新值，然后函数执行结果被合并到最终的结果对象中。\n",
    "\n",
    "df.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.692199Z",
     "start_time": "2019-09-18T06:56:34.645325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A      B         C         D\n",
      "0  foo    one -0.746419 -0.727265\n",
      "1  bar    one -1.183160 -0.743046\n",
      "2  foo    two -0.268609 -0.771795\n",
      "3  bar  three  1.244494 -0.254125\n",
      "4  foo    two -0.441855  0.331644\n",
      "5  bar    two -0.353031  0.533953\n",
      "6  foo    one -0.939945 -0.051615\n",
      "7  foo  three -0.138468 -0.183802\n",
      "------\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002BC36F63E48> <class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "------\n",
      "            C         D\n",
      "A                      \n",
      "bar -0.097232 -0.154406\n",
      "foo -0.507059 -0.280566 <class 'pandas.core.frame.DataFrame'> \n",
      " Index(['C', 'D'], dtype='object')\n",
      "                  C         D\n",
      "A   B                        \n",
      "bar one   -1.183160 -0.743046\n",
      "    three  1.244494 -0.254125\n",
      "    two   -0.353031  0.533953\n",
      "foo one   -0.843182 -0.389440\n",
      "    three -0.138468 -0.183802\n",
      "    two   -0.355232 -0.220075 <class 'pandas.core.frame.DataFrame'> \n",
      " Index(['C', 'D'], dtype='object')\n",
      "A\n",
      "bar   -0.154406\n",
      "foo   -0.280566\n",
      "Name: D, dtype: float64 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 分组\n",
    "\n",
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "print(df)\n",
    "print('------')\n",
    "\n",
    "print(df.groupby('A'), type(df.groupby('A')))\n",
    "print('------')\n",
    "# 直接分组得到一个groupby对象，是一个中间数据，没有进行计算\n",
    "\n",
    "a = df.groupby('A').mean()\n",
    "b = df.groupby(['A','B']).mean()\n",
    "c = df.groupby(['A'])['D'].mean()  # 以A分组，算D的平均值\n",
    "print(a,type(a),'\\n',a.columns)\n",
    "print(b,type(b),'\\n',b.columns)\n",
    "print(c,type(c))\n",
    "# 通过分组后的计算，得到一个新的dataframe\n",
    "# 默认axis = 0，以行来分组\n",
    "# 可单个或多个（[]）列分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.775975Z",
     "start_time": "2019-09-18T06:56:34.694195Z"
    },
    "scrolled": false
   },
   "source": [
    "# 分组 - 可迭代对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.775975Z",
     "start_time": "2019-09-18T06:56:34.694195Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y\n",
      "0  A  1\n",
      "1  B  4\n",
      "2  A  3\n",
      "3  B  2\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002BC36EB2CF8> <class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "-----\n",
      "[('A',    X  Y\n",
      "0  A  1\n",
      "2  A  3), ('B',    X  Y\n",
      "1  B  4\n",
      "3  B  2)] → 可迭代对象，直接生成list\n",
      "\n",
      "('A',    X  Y\n",
      "0  A  1\n",
      "2  A  3) → 以元祖形式显示\n",
      "\n",
      "A\n",
      "   X  Y\n",
      "0  A  1\n",
      "2  A  3\n",
      "###\n",
      "B\n",
      "   X  Y\n",
      "1  B  4\n",
      "3  B  2\n",
      "###\n",
      "-----\n",
      "   X  Y\n",
      "0  A  1\n",
      "2  A  3 \n",
      "\n",
      "   X  Y\n",
      "1  B  4\n",
      "3  B  2 \n",
      "\n",
      "-----\n",
      "{'A': Int64Index([0, 2], dtype='int64'), 'B': Int64Index([1, 3], dtype='int64')}\n",
      "Int64Index([0, 2], dtype='int64')\n",
      "-----\n",
      "X\n",
      "A    2\n",
      "B    2\n",
      "dtype: int64 <class 'pandas.core.series.Series'>\n",
      "-----\n",
      "     A      B         C         D\n",
      "0  foo    one  0.114203 -0.251325\n",
      "1  bar    one  0.930476  1.142140\n",
      "2  foo    two  0.738221 -1.935856\n",
      "3  bar  three  1.570125  0.763274\n",
      "4  foo    two -1.248058 -0.259456\n",
      "5  bar    two -0.905964  0.918795\n",
      "6  foo    one  1.408891  0.550826\n",
      "7  foo  three  1.147663 -0.655476\n",
      "{('bar', 'one'): Int64Index([1], dtype='int64'), ('bar', 'three'): Int64Index([3], dtype='int64'), ('bar', 'two'): Int64Index([5], dtype='int64'), ('foo', 'one'): Int64Index([0, 6], dtype='int64'), ('foo', 'three'): Int64Index([7], dtype='int64'), ('foo', 'two'): Int64Index([2, 4], dtype='int64')}\n",
      "Int64Index([7], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'X' : ['A', 'B', 'A', 'B'], 'Y' : [1, 4, 3, 2]})\n",
    "print(df)\n",
    "print(df.groupby('X'), type(df.groupby('X')))\n",
    "print('-----')\n",
    "\n",
    "print(list(df.groupby('X')), '→ 可迭代对象，直接生成list\\n')\n",
    "print(list(df.groupby('X'))[0], '→ 以元祖形式显示\\n')\n",
    "for n,g in df.groupby('X'):\n",
    "    print(n)\n",
    "    print(g)\n",
    "    print('###')\n",
    "print('-----')\n",
    "# n是组名，g是分组后的Dataframe\n",
    "\n",
    "print(df.groupby(['X']).get_group('A'),'\\n')\n",
    "print(df.groupby(['X']).get_group('B'),'\\n')\n",
    "print('-----')\n",
    "# .get_group()提取分组后的组\n",
    "\n",
    "grouped = df.groupby(['X'])\n",
    "print(grouped.groups)\n",
    "print(grouped.groups['A'])  # 也可写：df.groupby('X').groups['A']\n",
    "print('-----')\n",
    "# .groups：将分组后的groups转为dict\n",
    "# 可以字典索引方法来查看groups里的元素\n",
    "\n",
    "sz = grouped.size()\n",
    "print(sz,type(sz))\n",
    "print('-----')\n",
    "# .size()：查看分组后的长度\n",
    "\n",
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "grouped = df.groupby(['A','B']).groups\n",
    "print(df)\n",
    "print(grouped)\n",
    "print(grouped[('foo', 'three')])\n",
    "# 按照两个列进行分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.806893Z",
     "start_time": "2019-09-18T06:56:34.778969Z"
    }
   },
   "source": [
    "# 其他轴上的分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:28:21.305514Z",
     "start_time": "2019-09-18T12:28:21.225373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2 key1 key2\n",
      "0  0.660716  0.777430    a  one\n",
      "1  0.810410  0.685187    b  two\n",
      "data1    float64\n",
      "data2    float64\n",
      "key1      object\n",
      "key2      object\n",
      "dtype: object\n",
      "-----\n",
      "float64\n",
      "      data1     data2\n",
      "0  0.660716  0.777430\n",
      "1  0.810410  0.685187\n",
      "##\n",
      "object\n",
      "  key1 key2\n",
      "0    a  one\n",
      "1    b  two\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'data1':np.random.rand(2),\n",
    "                  'data2':np.random.rand(2),\n",
    "                  'key1':['a','b'],\n",
    "                  'key2':['one','two']})\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "print('-----')\n",
    "for n,p in df.groupby(df.dtypes, axis=1):\n",
    "    print(n)\n",
    "    print(p)\n",
    "    print('##')\n",
    "# 按照值类型分列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.840804Z",
     "start_time": "2019-09-18T06:56:34.809922Z"
    }
   },
   "source": [
    "# 通过字典或者Series分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.840804Z",
     "start_time": "2019-09-18T06:56:34.809922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n",
      "-----\n",
      "   one  two\n",
      "0    1    5\n",
      "1    9   13\n",
      "2   17   21\n",
      "3   25   29\n",
      "-----\n",
      "a      one\n",
      "b      one\n",
      "c      two\n",
      "d      two\n",
      "e    three\n",
      "dtype: object \n",
      "\n",
      "one      2\n",
      "three    1\n",
      "two      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape(4,4),\n",
    "                  columns = ['a','b','c','d'])\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "mapping = {'a':'one','b':'one','c':'two','d':'two','e':'three'}\n",
    "by_column = df.groupby(mapping, axis = 1)\n",
    "print(by_column.sum())\n",
    "print('-----')\n",
    "# mapping中，a、b列对应的为one，c、d列对应的为two，以字典来分组\n",
    "\n",
    "s = pd.Series(mapping)\n",
    "print(s,'\\n')\n",
    "print(s.groupby(s).count())\n",
    "# s中，index中a、b对应的为one，c、d对应的为two，以Series来分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.864738Z",
     "start_time": "2019-09-18T06:56:34.844793Z"
    }
   },
   "source": [
    "# 通过函数分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:28:46.714138Z",
     "start_time": "2019-09-18T12:28:46.693194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      a   b   c   d\n",
      "abc   0   1   2   3\n",
      "bcd   4   5   6   7\n",
      "aa    8   9  10  11\n",
      "b    12  13  14  15 \n",
      "\n",
      "    a   b   c   d\n",
      "1  12  13  14  15\n",
      "2   8   9  10  11\n",
      "3   4   6   8  10\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.arange(16).reshape(4,4),\n",
    "                  columns = ['a','b','c','d'],\n",
    "                 index = ['abc','bcd','aa','b'])\n",
    "print(df,'\\n')\n",
    "print(df.groupby(len).sum())\n",
    "# 按照字母长度分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:34.933587Z",
     "start_time": "2019-09-18T06:56:34.877704Z"
    }
   },
   "source": [
    "# 分组计算函数方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:07.053870Z",
     "start_time": "2019-09-18T12:29:07.031874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.SeriesGroupBy object at 0x000002BC373EB4E0>\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "dtype: int64 → first：非NaN的第一个值\n",
      "\n",
      "1    10\n",
      "2    20\n",
      "3    30\n",
      "dtype: int64 → last：非NaN的最后一个值\n",
      "\n",
      "1    11\n",
      "2    22\n",
      "3    33\n",
      "dtype: int64 → sum：非NaN的和\n",
      "\n",
      "1     5.5\n",
      "2    11.0\n",
      "3    16.5\n",
      "dtype: float64 → mean：非NaN的平均值\n",
      "\n",
      "1     5.5\n",
      "2    11.0\n",
      "3    16.5\n",
      "dtype: float64 → median：非NaN的算术中位数\n",
      "\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "dtype: int64 → count：非NaN的值\n",
      "\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "dtype: int64 → min、max：非NaN的最小值、最大值\n",
      "\n",
      "1     6.363961\n",
      "2    12.727922\n",
      "3    19.091883\n",
      "dtype: float64 → std，var：非NaN的标准差和方差\n",
      "\n",
      "1    10\n",
      "2    40\n",
      "3    90\n",
      "dtype: int64 → prod：非NaN的积\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 10, 20, 30], index = [1, 2, 3, 1, 2, 3])\n",
    "grouped = s.groupby(level=0)  # 唯一索引用.groupby(level=0)，将同一个index的分为一组\n",
    "print(grouped)\n",
    "print(grouped.first(),'→ first：非NaN的第一个值\\n')\n",
    "print(grouped.last(),'→ last：非NaN的最后一个值\\n')\n",
    "print(grouped.sum(),'→ sum：非NaN的和\\n')\n",
    "print(grouped.mean(),'→ mean：非NaN的平均值\\n')\n",
    "print(grouped.median(),'→ median：非NaN的算术中位数\\n')\n",
    "print(grouped.count(),'→ count：非NaN的值\\n')\n",
    "print(grouped.min(),'→ min、max：非NaN的最小值、最大值\\n')\n",
    "print(grouped.std(),'→ std，var：非NaN的标准差和方差\\n')\n",
    "print(grouped.prod(),'→ prod：非NaN的积\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:07.693124Z",
     "start_time": "2019-09-18T12:29:07.634283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a         b         c         d\n",
      "0  1  0.585134  0.379874  0.780815\n",
      "1  1  0.060854  0.715580  0.518720\n",
      "2  2  0.574649  0.508345  0.320941\n",
      "3  2  0.431100  0.263913  0.392179\n",
      "          b                   c                   d          \n",
      "       mean       sum      mean       sum      mean       sum\n",
      "a                                                            \n",
      "1  0.322994  0.645988  0.547727  1.095455  0.649767  1.299535\n",
      "2  0.502874  1.005748  0.386129  0.772259  0.356560  0.713120\n",
      "    result1   result2\n",
      "a                    \n",
      "1  0.322994  0.645988\n",
      "2  0.502874  1.005748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 多函数计算：agg()\n",
    "\n",
    "df = pd.DataFrame({'a':[1,1,2,2],\n",
    "                  'b':np.random.rand(4),\n",
    "                  'c':np.random.rand(4),\n",
    "                  'd':np.random.rand(4),})\n",
    "print(df)\n",
    "print(df.groupby('a').agg(['mean',np.sum]))\n",
    "print(df.groupby('a')['b'].agg({'result1':np.mean,\n",
    "                               'result2':np.sum}))\n",
    "# 函数写法可以用str，或者np.方法\n",
    "# 可以通过list，dict传入，当用dict时，key名为columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:11.862653Z",
     "start_time": "2019-09-18T12:29:11.856703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  分组转换及一般性“拆分-应用-合并”\\n\\ntransform / apply\\n \\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  分组转换及一般性“拆分-应用-合并”\n",
    "\n",
    "transform / apply\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:35.005362Z",
     "start_time": "2019-09-18T06:56:34.999380Z"
    }
   },
   "source": [
    "# 数据分组转换,transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:30.446553Z",
     "start_time": "2019-09-18T12:29:30.392653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2 key1 key2\n",
      "0  0.256987  0.628805    a  one\n",
      "1  0.938458  0.240588    a  two\n",
      "2  0.668865  0.270616    b  one\n",
      "3  0.166046  0.017018    b  two\n",
      "4  0.209908  0.151179    a  one\n",
      "         data1     data2\n",
      "key1                    \n",
      "a     0.468451  0.340191\n",
      "b     0.417455  0.143817\n",
      "   mean_data1_x  mean_data2_x mean_key1 mean_key2  mean_data1_y  mean_data2_y\n",
      "0      0.256987      0.628805         a       one      0.468451      0.340191\n",
      "1      0.938458      0.240588         a       two      0.468451      0.340191\n",
      "4      0.209908      0.151179         a       one      0.468451      0.340191\n",
      "2      0.668865      0.270616         b       one      0.417455      0.143817\n",
      "3      0.166046      0.017018         b       two      0.417455      0.143817\n",
      "-----\n",
      "         data1     data2\n",
      "key2                    \n",
      "one   0.378586  0.350200\n",
      "two   0.552252  0.128803\n",
      "      data1     data2\n",
      "0  0.378586  0.350200\n",
      "1  0.552252  0.128803\n",
      "2  0.378586  0.350200\n",
      "3  0.552252  0.128803\n",
      "4  0.378586  0.350200\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'data1':np.random.rand(5),\n",
    "                  'data2':np.random.rand(5),\n",
    "                  'key1':list('aabba'),\n",
    "                  'key2':['one','two','one','two','one']})\n",
    "k_mean = df.groupby('key1').mean()\n",
    "print(df)\n",
    "print(k_mean)\n",
    "print(pd.merge(df,k_mean,left_on='key1',right_index=True).add_prefix('mean_'))  # .add_prefix('mean_')：添加前缀\n",
    "print('-----')\n",
    "# 通过分组、合并，得到一个包含均值的Dataframe\n",
    "\n",
    "print(df.groupby('key2').mean()) # 按照key2分组求均值\n",
    "print(df.groupby('key2').transform(np.mean))\n",
    "# data1、data2每个位置元素取对应分组列的均值\n",
    "# 字符串不能进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 一般化Groupby方法：apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:34.474687Z",
     "start_time": "2019-09-18T12:29:34.373250Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               data1     data2\n",
      "key1                          \n",
      "a    count  3.000000  3.000000\n",
      "     mean   0.278176  0.497334\n",
      "     std    0.224387  0.346168\n",
      "     min    0.090761  0.257315\n",
      "     25%    0.153852  0.298923\n",
      "     50%    0.216943  0.340531\n",
      "     75%    0.371883  0.617344\n",
      "     max    0.526823  0.894156\n",
      "b    count  2.000000  2.000000\n",
      "     mean   0.709005  0.305300\n",
      "     std    0.310128  0.005954\n",
      "     min    0.489711  0.301090\n",
      "     25%    0.599358  0.303195\n",
      "     50%    0.709005  0.305300\n",
      "     75%    0.818652  0.307405\n",
      "     max    0.928299  0.309510\n",
      "           data1     data2 key1 key2\n",
      "key1                                \n",
      "a    0  0.090761  0.257315    a  one\n",
      "     1  0.216943  0.894156    a  two\n",
      "b    2  0.928299  0.301090    b  one\n",
      "     3  0.489711  0.309510    b  two \n",
      "\n",
      "key1   \n",
      "a     0    0.257315\n",
      "      1    0.894156\n",
      "      4    0.340531\n",
      "b     2    0.301090\n",
      "      3    0.309510\n",
      "Name: data2, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'data1':np.random.rand(5),\n",
    "                  'data2':np.random.rand(5),\n",
    "                  'key1':list('aabba'),\n",
    "                  'key2':['one','two','one','two','one']})\n",
    "\n",
    "print(df.groupby('key1').apply(lambda x: x.describe()))\n",
    "# apply直接运行其中的函数\n",
    "# 这里为匿名函数，直接描述分组后的统计量\n",
    "\n",
    "def f_df1(d,n):\n",
    "    return(d.sort_index()[:n])\n",
    "def f_df2(d,k1):\n",
    "    return(d[k1])\n",
    "print(df.groupby('key1').apply(f_df1,2),'\\n')\n",
    "print(df.groupby('key1').apply(f_df2,'data2'))\n",
    "print(type(df.groupby('key1').apply(f_df2,'data2')))\n",
    "# f_df1函数：返回排序后的前n行数据\n",
    "# f_df2函数：返回分组后表的k1列，结果为Series，层次化索引\n",
    "# 直接运行f_df函数\n",
    "# 参数直接写在后面，也可以为.apply(f_df,n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:38.109551Z",
     "start_time": "2019-09-18T12:29:38.101538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  透视表及交叉表\\n\\n类似excel数据透视 - pivot table / crosstab\\n \\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  透视表及交叉表\n",
    "\n",
    "类似excel数据透视 - pivot table / crosstab\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 透视表：pivot_table\n",
    "\n",
    "\n",
    "pd.pivot_table(data, values=None, index=None, columns=None, \n",
    "aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
    "\n",
    "## 透视表就是将指定原有DataFrame的列分别作为行索引和列索引，然后对指定的列应用聚集函数(默认情况下式mean函数)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:42.999757Z",
     "start_time": "2019-09-18T12:29:42.885890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date key    values\n",
      "0 2017-05-01   a  8.493685\n",
      "1 2017-05-02   b  1.345176\n",
      "2 2017-05-03   c  8.876519\n",
      "3 2017-05-01   d  7.054023\n",
      "4 2017-05-02   a  0.903263\n",
      "5 2017-05-03   b  3.690910\n",
      "6 2017-05-01   c  0.093970\n",
      "7 2017-05-02   d  5.693312\n",
      "8 2017-05-03   a  4.710600\n",
      "-----\n",
      "key                a         b         c         d\n",
      "date                                              \n",
      "2017-05-01  8.493685       NaN  0.093970  7.054023\n",
      "2017-05-02  0.903263  1.345176       NaN  5.693312\n",
      "2017-05-03  4.710600  3.690910  8.876519       NaN\n",
      "-----\n",
      "                values\n",
      "date       key        \n",
      "2017-05-01 a       1.0\n",
      "           c       1.0\n",
      "           d       1.0\n",
      "2017-05-02 a       1.0\n",
      "           b       1.0\n",
      "           d       1.0\n",
      "2017-05-03 a       1.0\n",
      "           b       1.0\n",
      "           c       1.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "date = ['2017-5-1','2017-5-2','2017-5-3']*3\n",
    "rng = pd.to_datetime(date)\n",
    "df = pd.DataFrame({'date':rng,\n",
    "                   'key':list('abcdabcda'),\n",
    "                  'values':np.random.rand(9)*10})\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(pd.pivot_table(df, values = 'values', index = 'date', columns = 'key', aggfunc=np.sum))  # 也可以写 aggfunc='sum'\n",
    "print('-----')\n",
    "# data：DataFrame对象\n",
    "# values：要聚合的列或列的列表\n",
    "# index：数据透视表的index，从原数据的列中筛选\n",
    "# columns：数据透视表的columns，从原数据的列中筛选\n",
    "# aggfunc：用于聚合的函数，默认为numpy.mean，支持numpy计算方法\n",
    "\n",
    "print(pd.pivot_table(df, values = 'values', index = ['date','key'], aggfunc=len))\n",
    "print('-----')\n",
    "# 这里就分别以date、key共同做数据透视，值为values：统计不同（date，key）情况下values的平均值\n",
    "# aggfunc=len(或者count)：计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 或者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:48.157289Z",
     "start_time": "2019-09-18T12:29:48.133317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   类别   产地  水果  数量  价格\n",
      "0  水果   美国  苹果   5   5\n",
      "1  水果   中国   梨   5   5\n",
      "2  水果   中国  草莓   9  10\n",
      "3  蔬菜   中国  番茄   3   3\n",
      "4  蔬菜  新西兰  黄瓜   2   3\n",
      "5  肉类  新西兰  羊肉  10  13\n",
      "6  肉类   美国  牛肉   8  20\n"
     ]
    }
   ],
   "source": [
    "df =pd.DataFrame({'类别':['水果','水果','水果','蔬菜','蔬菜','肉类','肉类'],\n",
    "                '产地':['美国','中国','中国','中国','新西兰','新西兰','美国'],\n",
    "                '水果':['苹果','梨','草莓','番茄','黄瓜','羊肉','牛肉'],\n",
    "               '数量':[5,5,9,3,2,10,8],\n",
    "               '价格':[5,5,10,3,3,13,20]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:38:29.727025Z",
     "start_time": "2019-09-18T03:38:29.702164Z"
    }
   },
   "source": [
    "# 按‘产地’和‘类别’重新索引，然后在‘价格’和‘数量’上执行mean函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:51.445786Z",
     "start_time": "2019-09-18T12:29:51.423876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>价格</th>\n",
       "      <th>数量</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>产地</th>\n",
       "      <th>类别</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">中国</th>\n",
       "      <th>水果</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蔬菜</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">新西兰</th>\n",
       "      <th>肉类</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>蔬菜</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">美国</th>\n",
       "      <th>水果</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>肉类</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          价格  数量\n",
       "产地  类别          \n",
       "中国  水果   7.5   7\n",
       "    蔬菜   3.0   3\n",
       "新西兰 肉类  13.0  10\n",
       "    蔬菜   3.0   2\n",
       "美国  水果   5.0   5\n",
       "    肉类  20.0   8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index=['产地','类别'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行索引为‘产地’，列索引为‘类别’，\n",
    "对‘价格’应用‘max’函数，并提供分项统计，缺失值填充0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:54.936630Z",
     "start_time": "2019-09-18T12:29:54.865818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>类别</th>\n",
       "      <th>水果</th>\n",
       "      <th>肉类</th>\n",
       "      <th>蔬菜</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>产地</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>中国</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>新西兰</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>美国</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "类别   水果  肉类  蔬菜  All\n",
       "产地                  \n",
       "中国   10   0   3   10\n",
       "新西兰   0  13   3   13\n",
       "美国    5  20   0   20\n",
       "All  10  20   3   20"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table('价格',index='产地',columns='类别',aggfunc='max',margins=True,fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T03:20:25.899492Z",
     "start_time": "2019-09-18T03:20:25.868812Z"
    }
   },
   "source": [
    "# 交叉表：crosstab   交叉表是用于统计分组频率的特殊透视表\n",
    "# 默认情况下，crosstab计算因子的频率表，比如用于str的数据透视分析\n",
    "# pd.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, dropna=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:57.990600Z",
     "start_time": "2019-09-18T12:29:57.938738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产地   中国  新西兰  美国  All\n",
      "类别                   \n",
      "水果    2    0   1    3\n",
      "肉类    0    1   1    2\n",
      "蔬菜    1    1   0    2\n",
      "All   3    2   2    7\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(df['类别'],df['产地'],margins=True)) # 按类别分组，统计各个分组中产地的频数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:58.270515Z",
     "start_time": "2019-09-18T12:29:58.260580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B    C\n",
      "0  1  3  1.0\n",
      "1  2  3  1.0\n",
      "2  2  4  NaN\n",
      "3  2  4  1.0\n",
      "4  2  4  1.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 2, 2, 2],\n",
    "                   'B': [3, 3, 4, 4, 4],\n",
    "                   'C': [1, 1, np.nan, 1, 1]})\n",
    "print(df)\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:29:59.050763Z",
     "start_time": "2019-09-18T12:29:59.015856Z"
    }
   },
   "source": [
    "# 如果crosstab只接收两个Series，它将提供一个频率表。\n",
    "# 用A的唯一值，统计B唯一值的出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:10.920465Z",
     "start_time": "2019-09-18T12:30:10.885556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B  3  4\n",
      "A      \n",
      "1  1  0\n",
      "2  1  3\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(df['A'],df['B']))\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:11.585305Z",
     "start_time": "2019-09-18T12:30:11.559165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    3    4\n",
      "A          \n",
      "1  0.2  0.0\n",
      "2  0.2  0.6\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(df['A'],df['B'],normalize=True))\n",
    "print('-----')\n",
    "# normalize：默认False，将所有值除以值的总和进行归一化 → 为True时候显示百分比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:12.752512Z",
     "start_time": "2019-09-18T12:30:12.662752Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    3    4\n",
      "A          \n",
      "1  1.0  NaN\n",
      "2  1.0  2.0\n",
      "-----\n",
      "B      3    4  All\n",
      "A                 \n",
      "1    1.0  NaN  1.0\n",
      "2    1.0  2.0  3.0\n",
      "All  2.0  2.0  4.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(df['A'],df['B'],values=df['C'],aggfunc=np.sum))\n",
    "print('-----')\n",
    "# values：可选，根据因子聚合的值数组\n",
    "# aggfunc：可选，如果未传递values数组，则计算频率表，如果传递数组，则按照指定计算\n",
    "# 这里相当于以A和B界定分组，计算出每组中第三个系列C的值\n",
    "\n",
    "print(pd.crosstab(df['A'],df['B'],values=df['C'],aggfunc=np.sum, margins=True))\n",
    "print('-----')\n",
    "# margins：布尔值，默认值False，添加行/列边距（小计）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:18.032996Z",
     "start_time": "2019-09-18T12:30:18.021073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  数据读取\\n\\n核心：read_table, read_csv, read_excel\\n \\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  数据读取\n",
    "\n",
    "核心：read_table, read_csv, read_excel\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T06:56:35.552898Z",
     "start_time": "2019-09-18T06:56:35.533949Z"
    }
   },
   "source": [
    "# 读取普通分隔数据：read_table\n",
    "# 可以读取txt，csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:32.471604Z",
     "start_time": "2019-09-18T12:30:32.433706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     va1  va3  va4\n",
      "va2               \n",
      "2      1    3    4\n",
      "3      2    4    5\n",
      "4      3    5    6\n",
      "5      4    6    7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('C:/Users/Hjx/Desktop/')\n",
    "data1 = pd.read_table('./data1.txt', delimiter=',',header = 0, index_col=1)\n",
    "print(data1)\n",
    "# delimiter：用于拆分的字符，也可以用sep：sep = ','\n",
    "# header：用做列名的序号，默认为0（第一行）\n",
    "# index_col：指定某列为行索引，否则自动索引0, 1, .....\n",
    "\n",
    "# read_table主要用于读取简单的数据，txt/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-18T12:30:33.781798Z",
     "start_time": "2019-09-18T12:30:33.274167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lining\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:188: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      省级政区代码    省级政区名称  地市级政区代码   地市级政区名称    年份 党委书记姓名  出生年份  出生月份  籍贯省份代码  \\\n",
      "0     130000       河北省   130100      石家庄市  2000    陈来立   NaN   NaN     NaN   \n",
      "1     130000       河北省   130100      石家庄市  2001    吴振华   NaN   NaN     NaN   \n",
      "2     130000       河北省   130100      石家庄市  2002    吴振华   NaN   NaN     NaN   \n",
      "3     130000       河北省   130100      石家庄市  2003    吴振华   NaN   NaN     NaN   \n",
      "4     130000       河北省   130100      石家庄市  2004    吴振华   NaN   NaN     NaN   \n",
      "5     130000       河北省   130100      石家庄市  2005    吴振华   NaN   NaN     NaN   \n",
      "6     130000       河北省   130100      石家庄市  2006    吴振华   NaN   NaN     NaN   \n",
      "7     130000       河北省   130100      石家庄市  2007    吴显国   NaN   NaN     NaN   \n",
      "8     130000       河北省   130100      石家庄市  2008    吴显国   NaN   NaN     NaN   \n",
      "9     130000       河北省   130100      石家庄市  2009     车俊   NaN   NaN     NaN   \n",
      "10    130000       河北省   130100      石家庄市  2010    孙瑞彬   NaN   NaN     NaN   \n",
      "11    130000       河北省   130200       唐山市  2000    白润璋   NaN   NaN     NaN   \n",
      "12    130000       河北省   130200       唐山市  2001    白润璋   NaN   NaN     NaN   \n",
      "13    130000       河北省   130200       唐山市  2002    白润璋   NaN   NaN     NaN   \n",
      "14    130000       河北省   130200       唐山市  2003     张和   NaN   NaN     NaN   \n",
      "15    130000       河北省   130200       唐山市  2004     张和   NaN   NaN     NaN   \n",
      "16    130000       河北省   130200       唐山市  2005     张和   NaN   NaN     NaN   \n",
      "17    130000       河北省   130200       唐山市  2006     张和   NaN   NaN     NaN   \n",
      "18    130000       河北省   130200       唐山市  2007     赵勇   NaN   NaN     NaN   \n",
      "19    130000       河北省   130200       唐山市  2008     赵勇   NaN   NaN     NaN   \n",
      "20    130000       河北省   130200       唐山市  2009     赵勇   NaN   NaN     NaN   \n",
      "21    130000       河北省   130200       唐山市  2010     赵勇   NaN   NaN     NaN   \n",
      "22    130000       河北省   130300      秦皇岛市  2000    王建忠   NaN   NaN     NaN   \n",
      "23    130000       河北省   130300      秦皇岛市  2001    王建忠   NaN   NaN     NaN   \n",
      "24    130000       河北省   130300      秦皇岛市  2002    王建忠   NaN   NaN     NaN   \n",
      "25    130000       河北省   130300      秦皇岛市  2003    宋长瑞   NaN   NaN     NaN   \n",
      "26    130000       河北省   130300      秦皇岛市  2004    宋长瑞   NaN   NaN     NaN   \n",
      "27    130000       河北省   130300      秦皇岛市  2005    宋长瑞   NaN   NaN     NaN   \n",
      "28    130000       河北省   130300      秦皇岛市  2006    宋长瑞   NaN   NaN     NaN   \n",
      "29    130000       河北省   130300      秦皇岛市  2007    王三堂   NaN   NaN     NaN   \n",
      "...      ...       ...      ...       ...   ...    ...   ...   ...     ...   \n",
      "3633  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2003    NaN   NaN   NaN     NaN   \n",
      "3634  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2004    NaN   NaN   NaN     NaN   \n",
      "3635  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2005    NaN   NaN   NaN     NaN   \n",
      "3636  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2006    NaN   NaN   NaN     NaN   \n",
      "3637  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2007    NaN   NaN   NaN     NaN   \n",
      "3638  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2008    NaN   NaN   NaN     NaN   \n",
      "3639  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2009    NaN   NaN   NaN     NaN   \n",
      "3640  650000  新疆维吾尔自治区   654000  伊犁哈萨克自治州  2010    NaN   NaN   NaN     NaN   \n",
      "3641  650000  新疆维吾尔自治区   654200      塔城地区  2000    NaN   NaN   NaN     NaN   \n",
      "3642  650000  新疆维吾尔自治区   654200      塔城地区  2001    NaN   NaN   NaN     NaN   \n",
      "3643  650000  新疆维吾尔自治区   654200      塔城地区  2002    NaN   NaN   NaN     NaN   \n",
      "3644  650000  新疆维吾尔自治区   654200      塔城地区  2003    NaN   NaN   NaN     NaN   \n",
      "3645  650000  新疆维吾尔自治区   654200      塔城地区  2004    NaN   NaN   NaN     NaN   \n",
      "3646  650000  新疆维吾尔自治区   654200      塔城地区  2005    NaN   NaN   NaN     NaN   \n",
      "3647  650000  新疆维吾尔自治区   654200      塔城地区  2006    NaN   NaN   NaN     NaN   \n",
      "3648  650000  新疆维吾尔自治区   654200      塔城地区  2007    NaN   NaN   NaN     NaN   \n",
      "3649  650000  新疆维吾尔自治区   654200      塔城地区  2008    NaN   NaN   NaN     NaN   \n",
      "3650  650000  新疆维吾尔自治区   654200      塔城地区  2009    NaN   NaN   NaN     NaN   \n",
      "3651  650000  新疆维吾尔自治区   654200      塔城地区  2010    NaN   NaN   NaN     NaN   \n",
      "3652  650000  新疆维吾尔自治区   654300     阿勒泰地区  2000    NaN   NaN   NaN     NaN   \n",
      "3653  650000  新疆维吾尔自治区   654300     阿勒泰地区  2001    NaN   NaN   NaN     NaN   \n",
      "3654  650000  新疆维吾尔自治区   654300     阿勒泰地区  2002    NaN   NaN   NaN     NaN   \n",
      "3655  650000  新疆维吾尔自治区   654300     阿勒泰地区  2003    NaN   NaN   NaN     NaN   \n",
      "3656  650000  新疆维吾尔自治区   654300     阿勒泰地区  2004    NaN   NaN   NaN     NaN   \n",
      "3657  650000  新疆维吾尔自治区   654300     阿勒泰地区  2005    NaN   NaN   NaN     NaN   \n",
      "3658  650000  新疆维吾尔自治区   654300     阿勒泰地区  2006    NaN   NaN   NaN     NaN   \n",
      "3659  650000  新疆维吾尔自治区   654300     阿勒泰地区  2007    NaN   NaN   NaN     NaN   \n",
      "3660  650000  新疆维吾尔自治区   654300     阿勒泰地区  2008    NaN   NaN   NaN     NaN   \n",
      "3661  650000  新疆维吾尔自治区   654300     阿勒泰地区  2009    NaN   NaN   NaN     NaN   \n",
      "3662  650000  新疆维吾尔自治区   654300     阿勒泰地区  2010    NaN   NaN   NaN     NaN   \n",
      "\n",
      "     籍贯省份名称  ...   民族   教育 是否是党校教育（是=1，否=0） 专业：人文 专业：社科  专业：理工  专业：农科  专业：医科  \\\n",
      "0       NaN  ...  NaN   硕士              1.0   NaN   NaN    NaN    NaN    NaN   \n",
      "1       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "2       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "3       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "4       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "5       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "6       NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "7       NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "8       NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "9       NaN  ...  NaN   本科              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "10      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "11      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "12      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "13      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "14      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "15      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "16      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "17      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "18      NaN  ...  NaN   博士              0.0   0.0   1.0    0.0    0.0    0.0   \n",
      "19      NaN  ...  NaN   博士              0.0   0.0   1.0    0.0    0.0    0.0   \n",
      "20      NaN  ...  NaN   博士              0.0   0.0   1.0    0.0    0.0    0.0   \n",
      "21      NaN  ...  NaN   博士              0.0   0.0   1.0    0.0    0.0    0.0   \n",
      "22      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "23      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "24      NaN  ...  NaN   本科              0.0   0.0   0.0    1.0    0.0    0.0   \n",
      "25      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "26      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "27      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "28      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "29      NaN  ...  NaN   硕士              1.0   0.0   1.0    0.0    0.0    0.0   \n",
      "...     ...  ...  ...  ...              ...   ...   ...    ...    ...    ...   \n",
      "3633    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3634    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3635    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3636    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3637    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3638    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3639    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3640    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3641    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3642    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3643    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3644    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3645    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3646    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3647    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3648    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3649    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3650    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3651    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3652    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3653    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3654    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3655    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3656    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3657    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3658    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3659    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3660    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3661    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "3662    NaN  ...  NaN  NaN              NaN   NaN   NaN    NaN    NaN    NaN   \n",
      "\n",
      "      入党年份  工作年份  \n",
      "0      NaN   NaN  \n",
      "1      NaN   NaN  \n",
      "2      NaN   NaN  \n",
      "3      NaN   NaN  \n",
      "4      NaN   NaN  \n",
      "5      NaN   NaN  \n",
      "6      NaN   NaN  \n",
      "7      NaN   NaN  \n",
      "8      NaN   NaN  \n",
      "9      NaN   NaN  \n",
      "10     NaN   NaN  \n",
      "11     NaN   NaN  \n",
      "12     NaN   NaN  \n",
      "13     NaN   NaN  \n",
      "14     NaN   NaN  \n",
      "15     NaN   NaN  \n",
      "16     NaN   NaN  \n",
      "17     NaN   NaN  \n",
      "18     NaN   NaN  \n",
      "19     NaN   NaN  \n",
      "20     NaN   NaN  \n",
      "21     NaN   NaN  \n",
      "22     NaN   NaN  \n",
      "23     NaN   NaN  \n",
      "24     NaN   NaN  \n",
      "25     NaN   NaN  \n",
      "26     NaN   NaN  \n",
      "27     NaN   NaN  \n",
      "28     NaN   NaN  \n",
      "29     NaN   NaN  \n",
      "...    ...   ...  \n",
      "3633   NaN   NaN  \n",
      "3634   NaN   NaN  \n",
      "3635   NaN   NaN  \n",
      "3636   NaN   NaN  \n",
      "3637   NaN   NaN  \n",
      "3638   NaN   NaN  \n",
      "3639   NaN   NaN  \n",
      "3640   NaN   NaN  \n",
      "3641   NaN   NaN  \n",
      "3642   NaN   NaN  \n",
      "3643   NaN   NaN  \n",
      "3644   NaN   NaN  \n",
      "3645   NaN   NaN  \n",
      "3646   NaN   NaN  \n",
      "3647   NaN   NaN  \n",
      "3648   NaN   NaN  \n",
      "3649   NaN   NaN  \n",
      "3650   NaN   NaN  \n",
      "3651   NaN   NaN  \n",
      "3652   NaN   NaN  \n",
      "3653   NaN   NaN  \n",
      "3654   NaN   NaN  \n",
      "3655   NaN   NaN  \n",
      "3656   NaN   NaN  \n",
      "3657   NaN   NaN  \n",
      "3658   NaN   NaN  \n",
      "3659   NaN   NaN  \n",
      "3660   NaN   NaN  \n",
      "3661   NaN   NaN  \n",
      "3662   NaN   NaN  \n",
      "\n",
      "[3663 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# 读取excel数据：read_excel\n",
    "\n",
    "data3 = pd.read_excel('地市级党委书记数据库（2000-10）.xlsx',sheetname='中国人民共和国地市级党委书记数据库（2000-10）',header=0)\n",
    "print(data3)\n",
    "# io ：文件路径。\n",
    "# sheetname：返回多表使用sheetname=[0,1],若sheetname=None是返回全表 → ① int/string 返回的是dataframe ②而none和list返回的是dict\n",
    "# header：指定列名行，默认0，即取第一行\n",
    "# index_col：指定列为索引列，也可以使用u”strings”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
